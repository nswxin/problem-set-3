---
title: "Problem Set 3"
author: "Pete Cuppernull"
date: "2/5/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(rsample)
library(glmnet)
library(leaps)
library(rcfss)
library(patchwork)
```

#Conceptual Exercises

##Generate Data -- not sure how to get coefs exactly to 0?
```{r}
create_data <- function(){
  rnorm(1000, 0, 1)
}

error <- rnorm(1000, 0, 1)
data <- data.frame(replicate(20, create_data())) %>%
  cbind(error) %>%
  mutate(Y = X1+X2+X3+X4+X5 + X6+X7+X8+X9+X10 + X11+X12+X13+X14+X15 + error)


model <- lm(Y ~ X1+X2+X3+X4+X5 + X6+X7+X8+X9+X10 + X11+X12+X13+X14+X15+X16+X17+X18+X19+X20, data = data)

summary(model)
```

##Split Data -- do they actually only want 100 obs in training?
```{r}
data_clean <- data %>%
  select(-error)
split <- initial_split(data_clean, prop = .1) 
train <- training(split)
test <- testing(split)
```

##Best Subset Selection
```{r}
best_sub <- regsubsets(Y ~ ., 
                          data = train, 
                          nvmax = 40 
                          )

summary(best_sub)$outmat 

results_bestsub <- summary(best_sub)

results_best <- tibble(
  `adj_r2` = which.max(results_bestsub$adjr2), # Adjusted r-squared
  BIC = which.min(results_bestsub$bic), # Schwartz's information criterion
  `c_p` = which.min(results_bestsub$cp) # Mallows' Cp
) %>%
  gather(statistic, best)

predict.regsubsets <- function(object, newdata, id ,...) {
  form <- as.formula(Y ~ .) 
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  as.vector(mat[, xvars] %*% coefi, mode = "integer")
}

predict_all <- function(object, newdata, k){
  map(k, ~ predict.regsubsets(object, newdata, id = .x)) %>%
    set_names(k)
}

data_clean_cv_train <- vfold_cv(train, v = 10)

data_clean_cv_train <- data_clean_cv_train %>%
  mutate(model = map(splits, ~ regsubsets(Y ~ ., data = analysis(.x), nvmax = 40)),
         pred = map2(model, splits, ~ predict_all(.x, assessment(.y), k = 1:18))) %>%
  unnest(pred, .preserve = splits) %>%
  group_by(id) %>%
  mutate(k = 1:18,
         truth = map(splits, ~ assessment(.x)$Y)) %>%
  unnest(pred, truth) %>%
  group_by(id, k) %>%
  mse(truth = truth, estimate = pred) %>%
  group_by(k) %>%
  summarize(.estimate = mean(.estimate))

ggplot(data_clean_cv_train, aes(k, .estimate)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = which.min(data_clean_cv_train$.estimate), linetype = 2) +
  labs(title = "Subset selection",
       x = "Number of variables",
       y = "10-fold CV MSE")

```

The model has the lowest MSE for the training set with 15 predictors.

##Test MSE -- I need to figure out how to take the models generated by the training and run the test data through them
```{r}

```

##rest of Qs I need help

#Application Exercises
###Import Data
```{r}
gss_test <- read_csv("data/gss_test.csv")
gss_train <- read_csv("data/gss_train.csv")
```

##LS Linear Model
```{r}
lm_gss <- lm(egalit_scale ~ ., data = gss_train)

summary(lm_gss)
lm_gss_test <- predict(lm_gss, 
                newdata = gss_test)

lm_mse <- mse(gss_test, gss_test$egalit_scale, lm_gss_test)$.estimate
mse
```

The MSE of the test set for the least squares model is `r lm_mse`.

##Ridge Regression
```{r}
gss_train_x <- model.matrix(egalit_scale ~ ., gss_train)[, -1]
gss_train_y <- log(gss_train$egalit_scale)

gss_train_x <- model.matrix(egalit_scale ~ ., gss_test)[, -1]
gss_train_y <- log(gss_test$egalit_scale)
# First: ridge regression
gss_ridge <- glmnet(
  x = gss_train_x,
  y = gss_train_y,
  alpha = 0
)

plot(gss_ridge, xvar = "lambda")


# Tuning lambda
# Apply CV Ridge regression to ames data
gss_ridge_cv <- cv.glmnet(
  x = gss_train_x,
  y = gss_train_y,
  alpha = 0
)
lambda_min_ridge <- which(gss_ridge_cv$lambda == gss_ridge_cv$lambda.min)
ridge_mse <- gss_ridge_cv$cvm[lambda_min_ridge]
```

The MSE of the test set for the Ridge regression model is `r ridge_mse`.

## Lasso Regression
```{r}

# First: ridge regression
gss_lasso <- glmnet(
  x = gss_train_x,
  y = gss_train_y,
  alpha = 1
)

plot(gss_lasso, xvar = "lambda")


# Tuning lambda
# Apply CV Ridge regression to ames data
gss_lasso_cv <- cv.glmnet(
  x = gss_train_x,
  y = gss_train_y,
  alpha = 1
)

lambda_min_lasso <- which(gss_lasso_cv$lambda == gss_lasso_cv$lambda.min)
lasso_mse <- gss_lasso_cv$cvm[lambda_min_lasso]
```

The MSE of the test set for the Ridge regression model is `r lasso_mse` and there are 18 non-zero coefficients.

## Elastic Net

```{r}
lasso    <- glmnet(gss_train_x, gss_train_y, alpha = 1.0) 
elastic1 <- glmnet(gss_train_x, gss_train_y, alpha = 0.25) 
elastic2 <- glmnet(gss_train_x, gss_train_y, alpha = 0.75) 
ridge    <- glmnet(gss_train_x, gss_train_y, alpha = 0.0)

fold_id <- sample(1:10, size = length(gss_train_y), replace = TRUE)

tuning_grid <- tibble::tibble(
  alpha      = seq(0, 1, by = .1),
  mse_min    = NA,
  mse_1se    = NA,
  lambda_min = NA,
  lambda_1se = NA
)

for(i in seq_along(tuning_grid$alpha)) {
  # fit CV model for each alpha value
  fit <- cv.glmnet(gss_train_x, 
                   gss_train_y, 
                   alpha = tuning_grid$alpha[i], 
                   foldid = fold_id)
  
  # extract MSE and lambda values
  tuning_grid$mse_min[i]    <- fit$cvm[fit$lambda == fit$lambda.min]
  tuning_grid$mse_1se[i]    <- fit$cvm[fit$lambda == fit$lambda.1se]
  tuning_grid$lambda_min[i] <- fit$lambda.min
  tuning_grid$lambda_1se[i] <- fit$lambda.1se
}

tuning_grid %>%
  mutate(se = mse_1se - mse_min) %>%
  ggplot(aes(alpha, mse_min)) +
  geom_line(size = 2) +
  geom_ribbon(aes(ymax = mse_min + se, ymin = mse_min - se), alpha = .25) +
  ggtitle("MSE Â± one standard error")

elastic_mse <- min(tuning_grid$mse_min)

##Non zero coefs
cv.glmnet(
  x = gss_train_x,
  y = gss_train_y,
  alpha = .4
)

```

The combination of $\alpha$ and $\lambda$ thatproduce the lwoest cross validation MSE are 0.4 and 0.102, respectively. The test MSE is `r elastic_mse` and there are 20 nonzero coefficients.